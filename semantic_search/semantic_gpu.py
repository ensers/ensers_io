# -*- coding: utf-8 -*-
"""semantic_gpu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qRzwALyUeq9uMuQFXxqfI3c5qN792co7
"""

!pip install farm-haystack['all-gpu']
!pip install farm-haystack['pinecone']
!pip install farm-haystack['PDFToTextConverter']
!pip install farm-haystack[ocr]
!wget --no-check-certificate https://dl.xpdfreader.com/xpdf-tools-linux-4.04.tar.gz
!tar -xvf xpdf-tools-linux-4.04.tar.gz && sudo cp xpdf-tools-linux-4.04/bin64/pdftotext /usr/local/bin

exit()

"""**Imports**"""

from haystack.document_stores import PineconeDocumentStore
from haystack.utils import convert_files_to_docs
from haystack.nodes import FARMReader
from haystack.nodes import PreProcessor
from haystack import Document
from haystack.nodes.retriever import EmbeddingRetriever
from haystack.pipelines import ExtractiveQAPipeline
from haystack.utils import print_answers
from haystack.nodes.answer_generator import RAGenerator
from haystack.pipelines import GenerativeQAPipeline
from haystack.nodes.connector import Crawler

"""**Initializing variables**"""

document_store = PineconeDocumentStore(
    api_key='8b1f9cc1-4214-458e-8f54-2ddacba4f5c9',
    index='semantic',
    environment='us-east1-gcp',
    similarity="cosine",
    embedding_dim=768
)

model = "deepset/roberta-base-squad2"
reader = FARMReader(model, use_gpu=True)


processor = PreProcessor(
    clean_empty_lines=True,
    clean_whitespace=True,
    clean_header_footer=True,
    split_by="word",
    split_length=100,
    split_respect_sentence_boundary=False,
    split_overlap=20
)


retriever=EmbeddingRetriever(
    document_store=document_store,
    embedding_model='flax-sentence-embeddings/all_datasets_v3_mpnet-base',
    model_format='sentence_transformers',
    use_gpu=True)

generator = RAGenerator(
    model_name_or_path="facebook/rag-sequence-nq",
    retriever=retriever,
    top_k=1,
    min_length=2
)

pipe = ExtractiveQAPipeline(reader, retriever)

pipeline=GenerativeQAPipeline(generator,retriever)

document_store.get_document_count()

"""**Loading Data from a directory**"""

doc_dir='/content/drive/MyDrive/semantic'
all_docs = convert_files_to_docs(dir_path=doc_dir)

"""**Pre-processing**"""

data_json=[
    {
        'content':doc.content.replace('\n',' ').replace('\x0c',''),
          'meta':{'name':doc.meta}
} for doc in all_docs
]

docs=processor.process(data_json)

docs[-1]

"""**Writing documents to document store**"""

document_store.write_documents(docs)

"""**Embedding documents in the document store**"""

document_store.update_embeddings(
    retriever,
    batch_size=256
)

document_store.get_embedding_count()

"""**Inference**"""

query='what should i do to  facilitate re-import of items like jewelery?'
prediction = pipe.run(
    query=query,
    params={"Retriever": {"top_k": 10}, "Reader": {"top_k": 3}}
)

print_answers(prediction)

result=pipeline.run(
    query=query,
    params={
        'Retriever':{'top_k':10},
        'Generator': {'top_k':1
        }
    }
)

print_answers(result)

"""**Clean-Up**"""

document_store.delete_documents(index='semantic')

# document_store.delete_index('semantic')